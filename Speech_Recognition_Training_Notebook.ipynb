{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech Recognition Training Notebook",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Code-CloudSG/SpeechRG/blob/main/Speech_Recognition_Training_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNFWX4V3Zu7s"
      },
      "source": [
        "# Speech Recognition Training Notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCxaBA1gJICK"
      },
      "source": [
        "\n",
        "This notebook demonstrates how to train a 20kb [Simple Audio Recognition](https://www.tensorflow.org/tutorials/sequences/audio_recognition) model for [TensorFlow Lite for Microcontrollers](https://tensorflow.org/lite/microcontrollers/overview). It will produce the same model used in the [micro_speech](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/micro_speech) example application.\n",
        "\n",
        "The model is designed to be used with [Google Colaboratory](https://colab.research.google.com).\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1cR5JJNYzWLlgSK9c16nnFLhxtW_bmO-p#offline=true&sandboxMode=true\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/examples/micro_speech/train_speech_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mpixtCtJPHk"
      },
      "source": [
        "The notebook runs Python scripts to train and freeze the model, and uses the TensorFlow Lite converter to convert it for use with TensorFlow Lite for Microcontrollers.\n",
        "\n",
        "**Training is much faster using GPU acceleration.** Before you proceed, ensure you are using a GPU runtime by going to **Runtime -> Change runtime type** and selecting **GPU**. Training 18,000 iterations will take 1.5-2 hours on a GPU runtime.\n",
        "\n",
        "## Configure training\n",
        "\n",
        "The following `os.environ` lines can be customized to set the words that will be trained for, and the steps and learning rate of the training. The default values will result in the same model that is used in the micro_speech example. Run the cell to set the configuration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMjI2a-4IsyN",
        "outputId": "31537ff6-a068-4b6f-c82d-f44eb513d6aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# A comma-delimited list of the words you want to train for.\n",
        "# The options are: yes,no,up,down,left,right,on,off,stop,go\n",
        "# All other words will be used to train an \"unknown\" category.\n",
        "WANTED_WORDS = [\"yes\", \"no\"]\n",
        "\n",
        "# The number of steps and learning rates can be specified as comma-separated\n",
        "# lists to define the rate at each stage. For example,\n",
        "# TRAINING_STEPS=15000,3000 and LEARNING_RATE=0.001,0.0001\n",
        "# will run 18,000 training loops in total, with a rate of 0.001 for the first\n",
        "# 15,000, and 0.0001 for the final 3,000.\n",
        "TRAINING_STEPS = [15000, 3000]\n",
        "LEARNING_RATE = [\"0.001\", \"0.0001\"]\n",
        "\n",
        "# Calculate the total number of steps, which is used to identify the checkpoint\n",
        "# file name.\n",
        "TOTAL_STEPS = sum(TRAINING_STEPS)\n",
        "\n",
        "# Print the configuration to confirm it\n",
        "!echo \"Training these words: {WANTED_WORDS}\"\n",
        "!echo \"Training steps in each stage: {TRAINING_STEPS}\"\n",
        "!echo \"Learning rate in each stage: {LEARNING_RATE}\"\n",
        "!echo \"Total number of training steps: {TOTAL_STEPS}\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training these words: ['yes', 'no']\n",
            "Training steps in each stage: [15000, 3000]\n",
            "Learning rate in each stage: ['0.001', '0.0001']\n",
            "Total number of training steps: 18000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT4hbq-GSgD4"
      },
      "source": [
        "# Connect to Google Drive\n",
        "\n",
        "This section connects the notebook with your Google Drive. Since Colab instances are ephemeral, we need somewhere more permanent to store the trained ML model. Running this cell mounts your Google Drive just like a regular folder at `/content/drive`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf-psq8uJeou",
        "outputId": "1815e114-39e3-495b-ae8f-1fb3a8ec9f3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os.path\n",
        "from google.colab import drive\n",
        "\n",
        "DRIVE_STORAGE_PATH = '/content/drive/My Drive/speech-recognition'\n",
        "\n",
        "def ensure_drive():\n",
        "  if not os.path.exists('/content/drive/My Drive'):\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    \n",
        "ensure_drive()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej9eyTYtI_RR"
      },
      "source": [
        "## Install dependencies\n",
        "\n",
        "Next, we'll install a GPU build of TensorFlow, so we can use GPU acceleration for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd1iM1o2ymvA",
        "outputId": "0cd1cccc-6c85-48b5-a697-d6ca4d0f736b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Replace Colab's default TensorFlow install with the pinned version used\n",
        "# for speech training.\n",
        "!pip uninstall -y tensorflow tensorflow_estimatorpip uninstall -y tensorflow tensorflow_estimator tensorboard\n",
        "!pip install -q tf-estimator-nightly==1.14.0.dev2019072901 tf-nightly-gpu==1.15.0.dev20190729"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Successfully uninstalled tensorflow-2.3.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-estimatorpip as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping uninstall as it is not installed.\u001b[0m\n",
            "Uninstalling tensorflow-estimator-2.3.0:\n",
            "  Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "Uninstalling tensorboard-2.3.0:\n",
            "  Successfully uninstalled tensorboard-2.3.0\n",
            "\u001b[K     |████████████████████████████████| 501kB 9.9MB/s \n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tf-nightly-gpu==1.15.0.dev20190729 (from versions: 2.4.0.dev20200902, 2.4.0.dev20200903, 2.4.0.dev20200904, 2.4.0.dev20200905, 2.4.0.dev20200906, 2.4.0.dev20200907, 2.4.0.dev20200908, 2.4.0.dev20200911, 2.4.0.dev20200912, 2.4.0.dev20200913, 2.4.0.dev20200914, 2.4.0.dev20200915, 2.4.0.dev20200916, 2.4.0.dev20200917, 2.4.0.dev20200918, 2.4.0.dev20200919, 2.4.0.dev20200920, 2.4.0.dev20200921, 2.4.0.dev20200922, 2.4.0.dev20200923, 2.4.0.dev20200924, 2.4.0.dev20200925, 2.4.0.dev20200926, 2.4.0.dev20200927, 2.4.0.dev20200928, 2.4.0.dev20200929, 2.4.0.dev20200930, 2.4.0.dev20201001, 2.4.0.dev20201002, 2.4.0.dev20201003, 2.4.0.dev20201004, 2.4.0.dev20201005, 2.4.0.dev20201007, 2.4.0.dev20201010, 2.4.0.dev20201011, 2.4.0.dev20201012, 2.4.0.dev20201014, 2.4.0.dev20201015, 2.4.0.dev20201016, 2.4.0.dev20201017, 2.4.0.dev20201018, 2.4.0.dev20201019, 2.4.0.dev20201020, 2.4.0.dev20201021, 2.4.0.dev20201022, 2.4.0.dev20201023, 2.5.0.dev20201024, 2.5.0.dev20201025, 2.5.0.dev20201026, 2.5.0.dev20201027, 2.5.0.dev20201028, 2.5.0.dev20201029)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tf-nightly-gpu==1.15.0.dev20190729\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfoVL_lYaRkU"
      },
      "source": [
        "## Download TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT6PCd82J4BO"
      },
      "source": [
        "We'll also clone the TensorFlow repository, which contains the scripts that train and freeze the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etSLy5EcZsp2",
        "outputId": "84753fb1-d57f-4527-b94f-13f1dbb26be3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Clone the repository from GitHub\n",
        "!git clone -q https://github.com/tensorflow/tensorflow\n",
        "# Check out a commit that has been tested to work\n",
        "# with the build of TensorFlow we're using\n",
        "!git -c advice.detachedHead=false -C tensorflow checkout -f 17ce384df70\n",
        "\n",
        "import subprocess\n",
        "subprocess.run(\n",
        "    ['git', '-C', 'tensorflow', 'apply', '-'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE,\n",
        "    encoding='utf-8',\n",
        "    check=True,\n",
        "    input=\"\"\"\\\n",
        "diff --git a/tensorflow/examples/speech_commands/train.py b/tensorflow/examples/speech_commands/train.py\n",
        "index 446e351cb8..431c2d3d34 100644\n",
        "--- a/tensorflow/examples/speech_commands/train.py\n",
        "+++ b/tensorflow/examples/speech_commands/train.py\n",
        "@@ -234,7 +234,7 @@ def main(_):\n",
        "             dropout_prob: 0.5\n",
        "         })\n",
        "     train_writer.add_summary(train_summary, training_step)\n",
        "-    tf.compat.v1.logging.info(\n",
        "+    tf.compat.v1.logging.debug(\n",
        "         'Step #%d: rate %f, accuracy %.1f%%, cross entropy %f' %\n",
        "         (training_step, learning_rate_value, train_accuracy * 100,\n",
        "          cross_entropy_value))\n",
        "\"\"\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking out files: 100% (19402/19402), done.\n",
            "HEAD is now at 17ce384df7 Share ownership of `UnboundedWorkQueue` between collective executor and executor manager.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['git', '-C', 'tensorflow', 'apply', '-'], returncode=0, stdout='', stderr='')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWkYEP2NOJME"
      },
      "source": [
        "### Optional: Visualize graph and training rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-2rS3ZyLVYq",
        "outputId": "bf58aeb7-7931-4c51-8e86-e85a872bb58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "!mkdir -p /content/retrain_logs\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/retrain_logs"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5ae3680f61ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir -p /content/retrain_logs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext tensorboard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorboard --logdir /content/retrain_logs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-63>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_load_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep7TSCcFaavF"
      },
      "source": [
        "## Create trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1O64yp5zBle",
        "outputId": "4cdcc3b4-88d1-4da1-8b80-21ec5ab00ddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import datetime\n",
        "\n",
        "wanted_words_str = ','.join(WANTED_WORDS)\n",
        "training_steps_str = ','.join([str(x) for x in TRAINING_STEPS])\n",
        "learning_rate_str = ','.join(LEARNING_RATE)\n",
        "\n",
        "TRAINING_RUN_NAME=\"{}-{}\".format(\n",
        "    wanted_words_str, datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"))\n",
        "TRAIN_DIR = f'{DRIVE_STORAGE_PATH}/{TRAINING_RUN_NAME}'\n",
        "!mkdir -p \"{TRAIN_DIR}\"\n",
        "\n",
        "# Suppress INFO messages from C++ logging--these will slow down Colab and \n",
        "# eventually crash the browser.\n",
        "#--verbosity=INFO \\\n",
        "!python tensorflow/tensorflow/examples/speech_commands/train.py \\\n",
        "--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n",
        "--wanted_words={wanted_words_str} --silence_percentage=25 \\\n",
        "--unknown_percentage=25 --quantize=1 \\\n",
        "--how_many_training_steps={training_steps_str} \\\n",
        "--learning_rate={learning_rate_str} --summaries_dir=/content/retrain_logs \\\n",
        "--data_dir=/content/speech_dataset --train_dir=\"{TRAIN_DIR}\"\n",
        "\n",
        "!python tensorflow/tensorflow/examples/speech_commands/freeze.py \\\n",
        "--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n",
        "--wanted_words={wanted_words_str} --quantize=1 \\\n",
        "--output_file=\"{TRAIN_DIR}/tiny_conv.pb\" \\\n",
        "--start_checkpoint=\"{TRAIN_DIR}/tiny_conv.ckpt-{TOTAL_STEPS}\"\n",
        "\n",
        "!toco \\\n",
        "--graph_def_file=\"{TRAIN_DIR}/tiny_conv.pb\" \\\n",
        "--output_file=\"{TRAIN_DIR}/tiny_conv.tflite\" \\\n",
        "--input_shapes=1,49,40,1 --input_arrays=Reshape_2 \\\n",
        "--output_arrays='labels_softmax' \\\n",
        "--inference_type=QUANTIZED_UINT8 --mean_values=0 --std_dev_values=9.8077\n",
        "\n",
        "print('Training completed')\n",
        "print(f'The frozen graph is: {TRAIN_DIR}/tiny_conv.pb')\n",
        "print(f'The tflite graph is: {TRAIN_DIR}/tiny_conv.tflite')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"tensorflow/tensorflow/examples/speech_commands/train.py\", line 79, in <module>\n",
            "    import tensorflow as tf\n",
            "ModuleNotFoundError: No module named 'tensorflow'\n",
            "Traceback (most recent call last):\n",
            "  File \"tensorflow/tensorflow/examples/speech_commands/freeze.py\", line 45, in <module>\n",
            "    import tensorflow as tf\n",
            "ModuleNotFoundError: No module named 'tensorflow'\n",
            "/bin/bash: toco: command not found\n",
            "Training completed\n",
            "The frozen graph is: /content/drive/My Drive/speech-recognition/yes,no-2020-10-30T12:39:47/tiny_conv.pb\n",
            "The tflite graph is: /content/drive/My Drive/speech-recognition/yes,no-2020-10-30T12:39:47/tiny_conv.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSwVAMRFOFE4"
      },
      "source": [
        "## Spot checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HqVZ9-j8FBL",
        "outputId": "949230be-ca0b-4f3d-e684-3c057dddcad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os.path\n",
        "if not os.path.exists('/content/speech_dataset'):\n",
        "  !wget https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
        "  !mkdir /content/speech_dataset\n",
        "  !tar -xzf speech_commands_v0.02.tar.gz -C /content/speech_dataset\n",
        "\n",
        "ensure_drive()\n",
        "\n",
        "\n",
        "for phrase in ('yes', 'no', 'right'):\n",
        "  wav = !ls -1 /content/speech_dataset/{phrase}/*.wav | head -n 1\n",
        "  wav = wav[0]\n",
        "\n",
        "  print('')\n",
        "  print(f'{phrase:10s} <' + '-' * 69)\n",
        "  !cd tensorflow && python tensorflow/examples/speech_commands/label_wav.py --graph=\"{TRAIN_DIR}/tiny_conv.pb\" --labels=\"{TRAIN_DIR}/tiny_conv_labels.txt\" --wav={wav} 2>/dev/null\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-30 12:39:57--  https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.63.128, 142.250.31.128, 172.217.5.240, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.63.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2428923189 (2.3G) [application/gzip]\n",
            "Saving to: ‘speech_commands_v0.02.tar.gz’\n",
            "\n",
            "speech_commands_v0. 100%[===================>]   2.26G   105MB/s    in 28s     \n",
            "\n",
            "2020-10-30 12:40:25 (83.9 MB/s) - ‘speech_commands_v0.02.tar.gz’ saved [2428923189/2428923189]\n",
            "\n",
            "\n",
            "yes        <---------------------------------------------------------------------\n",
            "\n",
            "no         <---------------------------------------------------------------------\n",
            "\n",
            "right      <---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}